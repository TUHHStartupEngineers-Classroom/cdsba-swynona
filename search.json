[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website every time before you want to upload changes."
  },
  {
    "objectID": "content/01_journal/02_statistics.html",
    "href": "content/01_journal/02_statistics.html",
    "title": "Statistical Concepts",
    "section": "",
    "text": "Note\n\n\n\nAssignment II on Statistical Concepts - final submission\n\n\n\n1 Task 1\n\nrandom_vars &lt;- readRDS(\"C:/Users/sophi/OneDrive/Desktop/Causal Data Science for Business Analytics 2023/gitclone/cdsba-swynona/assets/Causal_Data_Science_Data/random_vars.rds\")\n\nexpected_value_age &lt;- mean(random_vars$age, na.rm = TRUE)\nvariance_age &lt;- var(random_vars$age, na.rm = TRUE)\nstandard_deviation_age &lt;- sd(random_vars$age, na.rm = TRUE)\n\nprint(paste('Expected Value Age = ', expected_value_age))\n\n#&gt; [1] \"Expected Value Age =  33.471\"\n\nprint(paste('Variance Age = ', variance_age))\n\n#&gt; [1] \"Variance Age =  340.607766766767\"\n\nprint(paste('Standard Deviation Age = ', standard_deviation_age))\n\n#&gt; [1] \"Standard Deviation Age =  18.4555619466536\"\n\nexpected_value_income &lt;- mean(random_vars$income, na.rm = TRUE)\nvariance_income &lt;- var(random_vars$income, na.rm = TRUE)\nstandard_deviation_income &lt;- sd(random_vars$income, na.rm = TRUE)\n\nprint(paste('Expected Value Income = ', expected_value_income))\n\n#&gt; [1] \"Expected Value Income =  3510.731\"\n\nprint(paste('Variance Income = ', variance_income))\n\n#&gt; [1] \"Variance Income =  8625645.84448348\"\n\nprint(paste('Standard Deviation Income = ', standard_deviation_income))\n\n#&gt; [1] \"Standard Deviation Income =  2936.94498492626\"\n\n\n\n2 Task 2\nIt makes sense to compare the standard deviations of age and income. The standard deviation is a measure of the amount of variation, a low standard deviation means that the values tend to be close to the mean (expected value), while a high standard deviation means that the values are more spread out over a wider range. In this case, the standard deviation of age is approximately 18.46 years, and the standard deviation of income is approximately 2936.94 units. This means that the ages in the dataset are less spread out from the mean age than the incomes are from the mean income. This means there is more VARIABILITY in the INCOMES of the individuals in the dataset than in their AGES.\n\n3 Task 3\n\ncovariance &lt;- cov(random_vars$age, random_vars$income, use = \"na.or.complete\")\ncorrelation &lt;- cor(random_vars$age, random_vars$income, use = \"na.or.complete\")\n\nprint(paste('Covariance = ',covariance))\n\n#&gt; [1] \"Covariance =  29700.1468458458\"\n\nprint(paste('Correlation = ',correlation))\n\n#&gt; [1] \"Correlation =  0.547943162326477\"\n\n\n\n4 Task 4\nThe expected value (or mean) is often the easiest to interpret because it provides a measure of the “central tendency” or typical value of the data.\nIn this case, the expected value of age is approximately 33.47 years, which means that on average, the individuals in the dataset are around 33 years old. The expected value of income is approximately 3510.73 units, which means that on average, the individuals in the dataset earn around 3510 units of income.\nThe correlation, which is approximately 0.55, is also relatively straightforward to interpret. This value indicates a moderate positive relationship between age and income, meaning that as age increases, income tends to increase as well.\nVariance and standard deviation provide information about the spread or dispersion of the data, and covariance provides a measure of how much two variables change together. These measures can be a bit more difficult to interpret without additional context or information.\nFor example, the standard deviation of income is approximately 2936.94 units, but without knowing more about the distribution of income it’s hard to say exactly what this tells us. Similarly, the covariance is approximately 29700.15, but this value is difficult to interpret on its own because it depends on the units of measurement of the variables. The correlation coefficient, which is unitless and ranges from -1 to 1, is often easier to interpret.\n\n5 Task 5\n\nE_income_age_less_18 &lt;- mean(random_vars$income[random_vars$age &lt;= 18], na.rm = TRUE)\nE_income_age_18_65 &lt;- mean(random_vars$income[random_vars$age &gt;= 18 & random_vars$age &lt;= 65], na.rm = TRUE)\nE_income_age_greater_65 &lt;- mean(random_vars$income[random_vars$age &gt;= 65], na.rm = TRUE)\n\nprint(paste('5.1. Income less than Age 18 = ', E_income_age_less_18))\n\n#&gt; [1] \"5.1. Income less than Age 18 =  389.607438016529\"\n\nprint(paste('5.2. Income between Age 18 and Age 65 = ', E_income_age_18_65))\n\n#&gt; [1] \"5.2. Income between Age 18 and Age 65 =  4691.3779637378\"\n\nprint(paste('5.3. Income more than Age 65 = ', E_income_age_greater_65))\n\n#&gt; [1] \"5.3. Income more than Age 65 =  1777.23728813559\""
  },
  {
    "objectID": "content/01_journal/04_causality.html",
    "href": "content/01_journal/04_causality.html",
    "title": "Causality",
    "section": "",
    "text": "Note\n\n\n\nAssignment IV on Causality - final submission\n\n\n\nlibrary(ggplot2)\n\n#&gt; Warning: package 'ggplot2' was built under R version 4.2.3\n\nlibrary(dplyr)\n\n#&gt; Warning: package 'dplyr' was built under R version 4.2.3\n\n\n#&gt; \n#&gt; Attaching package: 'dplyr'\n\n\n#&gt; The following objects are masked from 'package:stats':\n#&gt; \n#&gt;     filter, lag\n\n\n#&gt; The following objects are masked from 'package:base':\n#&gt; \n#&gt;     intersect, setdiff, setequal, union\n\ndf &lt;- data.frame(\n  Year = c(1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008),\n  MathDoctorates = c(1122, 1123, 1177, 1083, 1050, 1010, 919, 993, 1076, 1205, 1325, 1393, 1399),  # Replace with actual data\n  UraniumStored = c(66.1, 65.9, 65.8, 58.3, 54.8, 55.6, 53.5, 45.6, 57.7, 64.7, 77.5, 81.2, 81.9)  # Replace with actual data\n)\n#DataSource\n#https://tylervigen.com/spurious-correlations\n#https://www.nsf.gov/statistics/infbrief/nsf11305/\n#https://www.census.gov/compendia/statab/2012/tables/12s0937.pdf\n\nggplot(df, aes(x=Year)) +\n  geom_line(aes(y=MathDoctorates, color=\"Math Doctorates\")) +\n  geom_line(aes(y=UraniumStored, color=\"Uranium Stored\")) +\n  scale_color_manual(values=c(\"Math Doctorates\"=\"red\", \"Uranium Stored\"=\"black\")) +\n  labs(title=\"Math doctorates awarded correlates with Uranium stored at US nuclear power plants\",\n       x=\"Year\",\n       y=\"Value\",\n       color=\"Legend\") +\n  theme_minimal()"
  },
  {
    "objectID": "content/01_journal/09_iv.html",
    "href": "content/01_journal/09_iv.html",
    "title": "Instrumental Variables",
    "section": "",
    "text": "Note\n\n\n\nAssignment IX on Instrumental Variables - final submission\n\n\n\n#install.packages('dagitty')\n#install.packages('estimatr')\n#install.packages('ggdag')\n#install.packages('ggplot2')\n#install.packages('dplyr')\nlibrary(dplyr)\n\n#&gt; Warning: package 'dplyr' was built under R version 4.2.3\n\n\n#&gt; \n#&gt; Attaching package: 'dplyr'\n\n\n#&gt; The following objects are masked from 'package:stats':\n#&gt; \n#&gt;     filter, lag\n\n\n#&gt; The following objects are masked from 'package:base':\n#&gt; \n#&gt;     intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\n#&gt; Warning: package 'ggplot2' was built under R version 4.2.3\n\nlibrary(ggdag) \n\n#&gt; Warning: package 'ggdag' was built under R version 4.2.3\n\n\n#&gt; \n#&gt; Attaching package: 'ggdag'\n\n\n#&gt; The following object is masked from 'package:stats':\n#&gt; \n#&gt;     filter\n\nlibrary(estimatr)\n\n#&gt; Warning: package 'estimatr' was built under R version 4.2.3\n\nlibrary(dagitty)\n\n#&gt; Warning: package 'dagitty' was built under R version 4.2.3\n\ndata &lt;- readRDS(\"C:/Users/sophi/OneDrive/Desktop/Causal Data Science for Business Analytics 2023/gitclone/cdsba-swynona/assets/Causal_Data_Science_Data/rand_enc.rds\")\ndata\n\n\n\n  \n\n\n# Define the DAG\ndag &lt;- dagify(time_spent ~ used_ftr + rand_enc,\n              used_ftr ~ rand_enc,\n              exposure = \"used_ftr\",\n              outcome = \"time_spent\")\n\nggdag(dag) + theme_dag()\n\n\n\n\n\n\nnaive_model &lt;- lm(time_spent ~ used_ftr, data = data)\nsummary(naive_model)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = time_spent ~ used_ftr, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -20.4950  -3.5393   0.0158   3.5961  20.5051 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 18.86993    0.06955   271.3   &lt;2e-16 ***\n#&gt; used_ftr    10.82269    0.10888    99.4   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 5.351 on 9998 degrees of freedom\n#&gt; Multiple R-squared:  0.497,  Adjusted R-squared:  0.497 \n#&gt; F-statistic:  9881 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\ncor.test(data$rand_enc, data$used_ftr)\n\n#&gt; \n#&gt;  Pearson's product-moment correlation\n#&gt; \n#&gt; data:  data$rand_enc and data$used_ftr\n#&gt; t = 20.88, df = 9998, p-value &lt; 2.2e-16\n#&gt; alternative hypothesis: true correlation is not equal to 0\n#&gt; 95 percent confidence interval:\n#&gt;  0.1855544 0.2231172\n#&gt; sample estimates:\n#&gt;      cor \n#&gt; 0.204411\n\nggplot(data, aes(x = rand_enc, y = used_ftr)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nfirst_stage &lt;- lm(used_ftr ~ rand_enc, data = data)\nsummary(first_stage)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = used_ftr ~ rand_enc, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -0.5071 -0.3062 -0.3062  0.4929  0.6938 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept) 0.306164   0.006851   44.69   &lt;2e-16 ***\n#&gt; rand_enc    0.200940   0.009624   20.88   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.4811 on 9998 degrees of freedom\n#&gt; Multiple R-squared:  0.04178,    Adjusted R-squared:  0.04169 \n#&gt; F-statistic:   436 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\npred_fs &lt;- predict(first_stage)\n\npred_vs_actl &lt;- tibble(\n  pred = pred_fs,\n  actl = data$used_ftr\n)\n\nggplot(pred_vs_actl, aes(x = pred, y = actl, color = as.factor(actl))) +\n  geom_jitter(alpha = .5) +\n  scale_color_discrete(labels = c(\"Did not use feature\", \"Used feature\")) +\n  theme(legend.title = element_blank())\n\n\n\n\n\n\nsecond_stage &lt;- lm(data$time_spent ~ first_stage$fitted.values)\nsummary(second_stage)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = data$time_spent ~ first_stage$fitted.values)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -25.8757  -5.4714  -0.3263   5.3807  25.6541 \n#&gt; \n#&gt; Coefficients:\n#&gt;                           Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)                19.3124     0.3129   61.72   &lt;2e-16 ***\n#&gt; first_stage$fitted.values   9.7382     0.7447   13.08   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 7.482 on 9998 degrees of freedom\n#&gt; Multiple R-squared:  0.01681,    Adjusted R-squared:  0.01672 \n#&gt; F-statistic:   171 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\nmodel_iv &lt;- iv_robust(time_spent ~ used_ftr | rand_enc, data = data)\nsummary(model_iv)\n\n#&gt; \n#&gt; Call:\n#&gt; iv_robust(formula = time_spent ~ used_ftr | rand_enc, data = data)\n#&gt; \n#&gt; Standard error type:  HC2 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value  Pr(&gt;|t|) CI Lower CI Upper   DF\n#&gt; (Intercept)   19.312     0.2248   85.89 0.000e+00   18.872    19.75 9998\n#&gt; used_ftr       9.738     0.5353   18.19 8.716e-73    8.689    10.79 9998\n#&gt; \n#&gt; Multiple R-squared:  0.4921 ,    Adjusted R-squared:  0.492 \n#&gt; F-statistic:   331 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\nnaive_estimate &lt;- coef(summary(naive_model))[\"used_ftr\", \"Estimate\"]\niv_estimate &lt;- coef(summary(model_iv))[\"used_ftr\", \"Estimate\"]\n\n# Print comparison\ncat(\"Naive Estimate: \", naive_estimate, \"\\n\")\n\n#&gt; Naive Estimate:  10.82269\n\ncat(\"IV Estimate: \", iv_estimate, \"\\n\")\n\n#&gt; IV Estimate:  9.738175"
  },
  {
    "objectID": "content/01_journal/07_matching.html",
    "href": "content/01_journal/07_matching.html",
    "title": "Matching and Subclassification",
    "section": "",
    "text": "Note\n\n\n\nAssignment VII on Matching adn Subclassification - final submission"
  },
  {
    "objectID": "content/01_journal/05_dag.html",
    "href": "content/01_journal/05_dag.html",
    "title": "Directed Acyclic Graphs",
    "section": "",
    "text": "Note\n\n\n\nAssignment V on Directed Acyclic Graphs - final submission\n\n\n\n1 Task 1\n\ninstall.packages(\"ggdag\")\n\n#&gt; Warning: package 'ggdag' is in use and will not be installed\n\ninstall.packages(\"dplyr\")\n\n#&gt; Warning: package 'dplyr' is in use and will not be installed\n\ninstall.packages(\"ggplot2\")\n\n#&gt; Warning: package 'ggplot2' is in use and will not be installed\n\nlibrary(ggdag)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Your data\nstore_data &lt;- data.frame(\n  Store = c(\"A\", \"B\", \"C\", \"D\"),\n  y0 = c(135, 121, NA, NA),\n  y1 = c(NA, NA, 102, 94),\n  d = c(0, 0, 1, 1),\n  y = c(135, 121, 102, 94),\n  ITE = c(NA, NA ,NA ,NA)\n)\n\n# Create a DAG\ndag &lt;- dagify(y ~ d + y0 + y1,\n              d ~ y0,\n              y0 ~ ITE,\n              y1 ~ ITE,\n              exposure = \"d\",\n              outcome = \"y\",\n              latent = c(\"ITE\"),\n              coords = list(x = c(ITE = 1, y0 = 2, d = 3, y1 = 4, y = 5),\n                            y = c(ITE = 2, y0 = 1, d = 2, y1 = 1, y = 2)))\n\n# Plot the DAG\nggdag(dag) \n\n\n\n\n\n\n\n\n2 Task 2\n\n# Load the data\ndata &lt;- readRDS(\"C:/Users/sophi/OneDrive/Desktop/Causal Data Science for Business Analytics 2023/gitclone/cdsba-swynona/assets/Causal_Data_Science_Data/customer_sat.rds\")\n\n# View the structure of the data\nstr(data)\n\n#&gt; tibble [15 × 3] (S3: tbl_df/tbl/data.frame)\n#&gt;  $ follow_ups  : num [1:15] 8 7 8 9 10 6 7 6 8 8 ...\n#&gt;  $ satisfaction: num [1:15] 40 45 47 44 50 55 60 62 59 65 ...\n#&gt;  $ subscription: chr [1:15] \"Elite\" \"Elite\" \"Elite\" \"Elite\" ...\n\nmodel1 &lt;- lm(satisfaction ~ follow_ups, data = data)\nsummary(model1)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ follow_ups, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -12.412  -5.257   1.733   4.506  12.588 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  78.8860     4.2717  18.467 1.04e-10 ***\n#&gt; follow_ups   -3.3093     0.6618  -5.001 0.000243 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 7.923 on 13 degrees of freedom\n#&gt; Multiple R-squared:  0.658,  Adjusted R-squared:  0.6316 \n#&gt; F-statistic: 25.01 on 1 and 13 DF,  p-value: 0.0002427\n\nmodel2 &lt;- lm(satisfaction ~ follow_ups + subscription, data = data)\nsummary(model2)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ follow_ups + subscription, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -4.3222 -2.1972  0.3167  2.2667  3.9944 \n#&gt; \n#&gt; Coefficients:\n#&gt;                      Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)           26.7667     6.6804   4.007  0.00206 ** \n#&gt; follow_ups             2.1944     0.7795   2.815  0.01682 *  \n#&gt; subscriptionPremium   44.7222     5.6213   7.956 6.88e-06 ***\n#&gt; subscriptionPremium+  18.0722     2.1659   8.344 4.37e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2.958 on 11 degrees of freedom\n#&gt; Multiple R-squared:  0.9597, Adjusted R-squared:  0.9487 \n#&gt; F-statistic: 87.21 on 3 and 11 DF,  p-value: 5.956e-08\n\n\n\n3 Task 3\nComparing coefficients and explanations :\nIn Model 1, the coefficient for follow_ups is -3.3093. This suggests that for each additional follow-up call, the satisfaction decreases by 3.3093 units, assuming all other variables are held constant. This model does not account for the subscription variable. In Model 2, the coefficient for follow_ups is 2.1944. This suggests that for each additional follow-up call, the satisfaction increases by 2.1944 units, when accounting for the subscription variable. This is a signifi cant change from Model 1, indicating that the subscription variable has a substantial impact on the relationship between follow_ups and satisfaction. The coefficients for subscriptionPremium and subscriptionPremium+ are 44.7222 and 18.0722respectively. This suggests that the subscription level significantly affects customer satisfaction. Specifically, customers with a Premium subscription are, on average, 44.7222 units more satisfied than those with a Starter subscription, assuming all other variables are held constant. Similarly, customers with a Premium+ subscription are, on average, 18.0722 units more satisfied than those with a Starter subscription, assuming all other variables are held constant. In conclusion, the subscription level appears to moderate the relationship between follow_upsand satisfaction. Without considering subscription, more follow-up calls are associated with lower satisfaction. However, when subscription is considered, more follow-up calls are associated with higher satisfaction. This could be because customers with higher-level subscriptions receive more benefits from follow-up calls, which increases their satisfaction. It’s also worth noting that customers with higher-level subscriptions are generally more satisfied.\n\n4 Task 4 - Plotting\n\nggplot(data, aes(x = follow_ups, y = satisfaction)) +\n  geom_point() +\n  facet_wrap(~subscription) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\") +\n  labs(title = \"Relationship between Follow-ups and Satisfaction\",\n       x = \"Follow-ups\",\n       y = \"Satisfaction\")\n\n#&gt; `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "content/01_journal/06_rct.html",
    "href": "content/01_journal/06_rct.html",
    "title": "Randomized Controlled Trials",
    "section": "",
    "text": "Note\n\n\n\nAssignment VI on Randomized Controlled Trials - final submission\n\n\n\nlibrary(ggplot2)\n\n# Load the data\ndata &lt;- readRDS('C:/Users/sophi/OneDrive/Desktop/Causal Data Science for Business Analytics 2023/gitclone/cdsba-swynona/assets/Causal_Data_Science_Data/abtest_online.rds')\n\n# Check whether the covariates are balanced across the groups\nggplot(data, aes(x=chatbot, y=previous_visit)) + geom_boxplot()\n\n\n\n\n\n\nggplot(data, aes(x=chatbot, fill=mobile_device)) + geom_bar(position=\"fill\")\n\n\n\n\n\n\n# Run a regression to find the effect of chatbot on sales\nmodel &lt;- lm(purchase_amount ~ chatbot, data=data)\nprint(summary(model))\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = purchase_amount ~ chatbot, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -16.702 -14.478  -9.626  13.922  64.648 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  16.7017     0.8374  19.944  &lt; 2e-16 ***\n#&gt; chatbotTRUE  -7.0756     1.1796  -5.998 2.79e-09 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 18.65 on 998 degrees of freedom\n#&gt; Multiple R-squared:  0.0348, Adjusted R-squared:  0.03383 \n#&gt; F-statistic: 35.98 on 1 and 998 DF,  p-value: 2.787e-09\n\n# Find subgroup-specific effects\nmodel_interaction &lt;- lm(purchase_amount ~ chatbot*mobile_device, data=data)\nprint(summary(model_interaction))\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = purchase_amount ~ chatbot * mobile_device, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -16.98 -14.54  -9.95  14.13  65.24 \n#&gt; \n#&gt; Coefficients:\n#&gt;                               Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)                    16.9797     1.0152  16.725   &lt;2e-16 ***\n#&gt; chatbotTRUE                    -7.0301     1.4284  -4.922    1e-06 ***\n#&gt; mobile_deviceTRUE              -0.8727     1.7987  -0.485    0.628    \n#&gt; chatbotTRUE:mobile_deviceTRUE  -0.1526     2.5369  -0.060    0.952    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 18.66 on 996 degrees of freedom\n#&gt; Multiple R-squared:  0.03534,    Adjusted R-squared:  0.03244 \n#&gt; F-statistic: 12.16 on 3 and 996 DF,  p-value: 8.034e-08\n\n# Compute a CATE for one exemplary group (for mobile users)\nmobile_users &lt;- subset(data, mobile_device == TRUE)\nmodel_mobile &lt;- lm(purchase_amount ~ chatbot, data=mobile_users)\ncate_mobile &lt;- coef(summary(model_mobile))\nprint(cate_mobile)\n\n#&gt;              Estimate Std. Error   t value     Pr(&gt;|t|)\n#&gt; (Intercept) 16.107009   1.498155 10.751227 3.575812e-23\n#&gt; chatbotTRUE -7.182663   2.115378 -3.395452 7.728973e-04\n\n# Use logistic regression with purchase as outcome variable\nmodel_logistic &lt;- glm(purchase ~ chatbot, data=data, family=binomial(link='logit'))\nprint(summary(model_logistic))\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = purchase ~ chatbot, family = binomial(link = \"logit\"), \n#&gt;     data = data)\n#&gt; \n#&gt; Deviance Residuals: \n#&gt;     Min       1Q   Median       3Q      Max  \n#&gt; -1.1706  -0.8849  -0.7897   1.1843   1.6232  \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept) -0.01613    0.08981  -0.180    0.857    \n#&gt; chatbotTRUE -0.98939    0.13484  -7.337 2.18e-13 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 1329.1  on 999  degrees of freedom\n#&gt; Residual deviance: 1273.3  on 998  degrees of freedom\n#&gt; AIC: 1277.3\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4\n\n# Interpret the coefficient for chatbot\nchatbot_coef &lt;- coef(model_logistic)\nodds_ratio &lt;- exp(chatbot_coef)\nprint(paste(\"The odds ratio for chatbot is\", odds_ratio, \". This means that for each unit increase in chatbot, the odds of purchase increase by a factor of\", odds_ratio, \".\"))\n\n#&gt; [1] \"The odds ratio for chatbot is 0.983999999999998 . This means that for each unit increase in chatbot, the odds of purchase increase by a factor of 0.983999999999998 .\"\n#&gt; [2] \"The odds ratio for chatbot is 0.371802498513822 . This means that for each unit increase in chatbot, the odds of purchase increase by a factor of 0.371802498513822 .\""
  },
  {
    "objectID": "content/01_journal/08_did.html",
    "href": "content/01_journal/08_did.html",
    "title": "Difference-in-Differences",
    "section": "",
    "text": "Note\n\n\n\nok edit comment\n\n\n\ndata &lt;- readRDS(\"C:/Users/sophi/OneDrive/Desktop/Causal Data Science for Business Analytics 2023/gitclone/cdsba-swynona/assets/Causal_Data_Science_Data/hospdd.rds\")\n\nlibrary(dplyr)\n\n#&gt; Warning: package 'dplyr' was built under R version 4.2.3\n\n\n#&gt; \n#&gt; Attaching package: 'dplyr'\n\n\n#&gt; The following objects are masked from 'package:stats':\n#&gt; \n#&gt;     filter, lag\n\n\n#&gt; The following objects are masked from 'package:base':\n#&gt; \n#&gt;     intersect, setdiff, setequal, union\n\n# Assuming 'procedure' is a binary variable indicating whether the hospital introduced the new procedure\n# and 'month' is a binary variable indicating before (0) and after (1) the introduction\n# and 'satis' is the patient satisfaction score\n\nmean_before_treatment &lt;- data %&gt;%\n  filter(procedure == 1, month &lt;= 6) %&gt;%\n  pull(satis) %&gt;%\n  mean()\n\nmean_after_treatment &lt;- data %&gt;%\n  filter(procedure == 1, month &gt; 6) %&gt;%\n  pull(satis) %&gt;%\n  mean()\n\nmean_before_control &lt;- data %&gt;%\n  filter(procedure == 0, month &lt;= 6) %&gt;%\n  pull(satis) %&gt;%\n  mean()\n\nmean_after_control &lt;- data %&gt;%\n  filter(procedure == 0, month &gt; 6) %&gt;%\n  pull(satis) %&gt;%\n  mean()\n\n# Assuming 'hospital' is a factor variable indicating the hospital id\n# and 'month' is a factor variable indicating the month of the survey\n\nmodel1 &lt;- lm(satis ~ procedure * month + month + hospital, data = data)\nsummary(model1)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satis ~ procedure * month + month + hospital, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.3319 -0.6546 -0.0917  0.5549  5.3541 \n#&gt; \n#&gt; Coefficients:\n#&gt;                  Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)      3.540037   0.031548 112.211  &lt; 2e-16 ***\n#&gt; procedure        0.812977   0.128855   6.309 2.97e-10 ***\n#&gt; month           -0.006094   0.006668  -0.914 0.360741    \n#&gt; hospital        -0.003673   0.001048  -3.506 0.000458 ***\n#&gt; procedure:month  0.013968   0.023445   0.596 0.551329    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.9836 on 7363 degrees of freedom\n#&gt; Multiple R-squared:  0.1325, Adjusted R-squared:  0.132 \n#&gt; F-statistic: 281.1 on 4 and 7363 DF,  p-value: &lt; 2.2e-16\n\nmodel2 &lt;- lm(satis ~ procedure * month + as.factor(month) + as.factor(hospital), data = data)\nsummary(model2)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satis ~ procedure * month + as.factor(month) + as.factor(hospital), \n#&gt;     data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.1880 -0.4642  0.0062  0.4545  4.3066 \n#&gt; \n#&gt; Coefficients: (1 not defined because of singularities)\n#&gt;                         Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)            3.1752470  0.0569452  55.760  &lt; 2e-16 ***\n#&gt; procedure              0.7567463  0.1238559   6.110 1.05e-09 ***\n#&gt; month                 -0.0035904  0.0058646  -0.612 0.540414    \n#&gt; as.factor(month)2     -0.0060173  0.0281595  -0.214 0.830798    \n#&gt; as.factor(month)3      0.0291493  0.0283075   1.030 0.303167    \n#&gt; as.factor(month)4      0.0178353  0.0352558   0.506 0.612953    \n#&gt; as.factor(month)5      0.0084081  0.0325291   0.258 0.796044    \n#&gt; as.factor(month)6      0.0106650  0.0319859   0.333 0.738822    \n#&gt; as.factor(month)7             NA         NA      NA       NA    \n#&gt; as.factor(hospital)2   0.4085664  0.0772439   5.289 1.26e-07 ***\n#&gt; as.factor(hospital)3   0.5336248  0.0793406   6.726 1.88e-11 ***\n#&gt; as.factor(hospital)4   0.2275102  0.0739432   3.077 0.002100 ** \n#&gt; as.factor(hospital)5  -0.1453529  0.0739432  -1.966 0.049367 *  \n#&gt; as.factor(hospital)6   0.4478634  0.0739432   6.057 1.46e-09 ***\n#&gt; as.factor(hospital)7   1.4044164  0.0714579  19.654  &lt; 2e-16 ***\n#&gt; as.factor(hospital)8   0.0718758  0.0763207   0.942 0.346347    \n#&gt; as.factor(hospital)9  -1.5185150  0.0782469 -19.407  &lt; 2e-16 ***\n#&gt; as.factor(hospital)10  1.6828446  0.0772439  21.786  &lt; 2e-16 ***\n#&gt; as.factor(hospital)11  0.2209653  0.0763207   2.895 0.003800 ** \n#&gt; as.factor(hospital)12 -0.0953034  0.0782469  -1.218 0.223269    \n#&gt; as.factor(hospital)13  0.4955931  0.0754680   6.567 5.49e-11 ***\n#&gt; as.factor(hospital)14  0.2330426  0.0793406   2.937 0.003322 ** \n#&gt; as.factor(hospital)15 -0.1444935  0.0793406  -1.821 0.068620 .  \n#&gt; as.factor(hospital)16  1.4142680  0.0772439  18.309  &lt; 2e-16 ***\n#&gt; as.factor(hospital)17  0.4235429  0.0805385   5.259 1.49e-07 ***\n#&gt; as.factor(hospital)18  0.1532761  0.0938190   1.634 0.102356    \n#&gt; as.factor(hospital)19 -0.7453017  0.0811646  -9.183  &lt; 2e-16 ***\n#&gt; as.factor(hospital)20  0.0473874  0.0791162   0.599 0.549219    \n#&gt; as.factor(hospital)21  1.1943370  0.0836256  14.282  &lt; 2e-16 ***\n#&gt; as.factor(hospital)22  0.7993153  0.0823359   9.708  &lt; 2e-16 ***\n#&gt; as.factor(hospital)23  0.7017202  0.0811646   8.646  &lt; 2e-16 ***\n#&gt; as.factor(hospital)24 -0.3081260  0.0866426  -3.556 0.000379 ***\n#&gt; as.factor(hospital)25  0.6464736  0.0927285   6.972 3.40e-12 ***\n#&gt; as.factor(hospital)26  0.2142471  0.0791162   2.708 0.006785 ** \n#&gt; as.factor(hospital)27 -0.3986544  0.0766128  -5.203 2.01e-07 ***\n#&gt; as.factor(hospital)28  0.7119953  0.0836256   8.514  &lt; 2e-16 ***\n#&gt; as.factor(hospital)29  0.2485512  0.0800957   3.103 0.001922 ** \n#&gt; as.factor(hospital)30 -0.1679220  0.0953664  -1.761 0.078313 .  \n#&gt; as.factor(hospital)31  0.5120848  0.0791162   6.473 1.03e-10 ***\n#&gt; as.factor(hospital)32 -0.3233456  0.0800957  -4.037 5.47e-05 ***\n#&gt; as.factor(hospital)33 -0.4539752  0.0791162  -5.738 9.96e-09 ***\n#&gt; as.factor(hospital)34 -0.0004123  0.0746075  -0.006 0.995590    \n#&gt; as.factor(hospital)35  0.3541110  0.0766128   4.622 3.86e-06 ***\n#&gt; as.factor(hospital)36  2.1381425  0.0773833  27.631  &lt; 2e-16 ***\n#&gt; as.factor(hospital)37  0.1404036  0.0927285   1.514 0.130034    \n#&gt; as.factor(hospital)38 -0.0868060  0.0782151  -1.110 0.267106    \n#&gt; as.factor(hospital)39 -0.0234969  0.0823359  -0.285 0.775362    \n#&gt; as.factor(hospital)40  1.1215331  0.0782151  14.339  &lt; 2e-16 ***\n#&gt; as.factor(hospital)41 -0.1497346  0.0766128  -1.954 0.050688 .  \n#&gt; as.factor(hospital)42  0.8811369  0.0850532  10.360  &lt; 2e-16 ***\n#&gt; as.factor(hospital)43 -0.7724325  0.0811646  -9.517  &lt; 2e-16 ***\n#&gt; as.factor(hospital)44  0.0344120  0.0904362   0.381 0.703577    \n#&gt; as.factor(hospital)45 -0.2137495  0.0766128  -2.790 0.005284 ** \n#&gt; as.factor(hospital)46  0.0784915  0.0823359   0.953 0.340466    \n#&gt; procedure:month        0.0165894  0.0216427   0.767 0.443396    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.7239 on 7314 degrees of freedom\n#&gt; Multiple R-squared:  0.5333, Adjusted R-squared:  0.5299 \n#&gt; F-statistic: 157.7 on 53 and 7314 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "content/01_journal/01_probability.html",
    "href": "content/01_journal/01_probability.html",
    "title": "Probability Theory",
    "section": "",
    "text": "Note\n\n\n\nAssignment I on Probability Theory - final submission"
  },
  {
    "objectID": "content/01_journal/01_probability.html#header-2",
    "href": "content/01_journal/01_probability.html#header-2",
    "title": "Probability Theory",
    "section": "\n5.1 Header 2",
    "text": "5.1 Header 2\nHeader 3\nHeader 4\nHeader 5\nHeader 6"
  },
  {
    "objectID": "content/01_journal/03_regression.html",
    "href": "content/01_journal/03_regression.html",
    "title": "Regression and Statistical Inference",
    "section": "",
    "text": "Note\n\n\n\nAssignment III on Regression and Statistical Inference - final submission\n\n\n\n1 Task 1\n\ninstall.packages(\"tidyverse\")\n\n#&gt; Warning: package 'tidyverse' is in use and will not be installed\n\nlibrary(tidyverse)\n\ndata &lt;- readRDS(\"C:/Users/sophi/OneDrive/Desktop/Causal Data Science for Business Analytics 2023/gitclone/cdsba-swynona/assets/Causal_Data_Science_Data/car_prices.rds\")\nprint(dim(data))\n\n#&gt; [1] 181  22\n\n\n\n2 Task 2\nType of Data is seen below.\n\nstr(data)\n\n#&gt; tibble [181 × 22] (S3: tbl_df/tbl/data.frame)\n#&gt;  $ aspiration      : chr [1:181] \"std\" \"std\" \"std\" \"std\" ...\n#&gt;  $ doornumber      : chr [1:181] \"two\" \"two\" \"two\" \"four\" ...\n#&gt;  $ carbody         : chr [1:181] \"convertible\" \"convertible\" \"hatchback\" \"sedan\" ...\n#&gt;  $ drivewheel      : chr [1:181] \"rwd\" \"rwd\" \"rwd\" \"fwd\" ...\n#&gt;  $ enginelocation  : chr [1:181] \"front\" \"front\" \"front\" \"front\" ...\n#&gt;  $ wheelbase       : num [1:181] 88.6 88.6 94.5 99.8 99.4 ...\n#&gt;  $ carlength       : num [1:181] 169 169 171 177 177 ...\n#&gt;  $ carwidth        : num [1:181] 64.1 64.1 65.5 66.2 66.4 66.3 71.4 71.4 71.4 67.9 ...\n#&gt;  $ carheight       : num [1:181] 48.8 48.8 52.4 54.3 54.3 53.1 55.7 55.7 55.9 52 ...\n#&gt;  $ curbweight      : num [1:181] 2548 2548 2823 2337 2824 ...\n#&gt;  $ enginetype      : chr [1:181] \"dohc\" \"dohc\" \"ohcv\" \"ohc\" ...\n#&gt;  $ cylindernumber  : chr [1:181] \"four\" \"four\" \"six\" \"four\" ...\n#&gt;  $ enginesize      : num [1:181] 130 130 152 109 136 136 136 136 131 131 ...\n#&gt;  $ fuelsystem      : chr [1:181] \"mpfi\" \"mpfi\" \"mpfi\" \"mpfi\" ...\n#&gt;  $ boreratio       : num [1:181] 3.47 3.47 2.68 3.19 3.19 3.19 3.19 3.19 3.13 3.13 ...\n#&gt;  $ stroke          : num [1:181] 2.68 2.68 3.47 3.4 3.4 3.4 3.4 3.4 3.4 3.4 ...\n#&gt;  $ compressionratio: num [1:181] 9 9 9 10 8 8.5 8.5 8.5 8.3 7 ...\n#&gt;  $ horsepower      : num [1:181] 111 111 154 102 115 110 110 110 140 160 ...\n#&gt;  $ peakrpm         : num [1:181] 5000 5000 5000 5500 5500 5500 5500 5500 5500 5500 ...\n#&gt;  $ citympg         : num [1:181] 21 21 19 24 18 19 19 19 17 16 ...\n#&gt;  $ highwaympg      : num [1:181] 27 27 26 30 22 25 25 25 20 22 ...\n#&gt;  $ price           : num [1:181] 13495 16500 16500 13950 17450 ...\n\n\nQ : What data types do you see? A : Char and number\nQ : How do numbers differ from strings regarding their data type? A : The main difference between character (or string) and numeric data types is that numeric data can be used in mathematical operations, while character data cannot. For example, you can add, subtract, multiply, or divide numbers, but you cannot perform these operations on text or strings. Instead, strings are typically used for text manipulation operations, such as concatenation, substring, etc.\n\n3 Task 3\nRun linear regression\n\n#assume 'price' is the dependent variable and all other variables are independent\nmodel &lt;- lm(price ~ ., data = data)\nsummary(model)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ ., data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt;  -5662  -1120      0    798   9040 \n#&gt; \n#&gt; Coefficients:\n#&gt;                        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)          -36269.965  15460.866  -2.346 0.020354 *  \n#&gt; aspirationturbo        1846.206   1041.391   1.773 0.078386 .  \n#&gt; doornumbertwo           242.523    571.929   0.424 0.672172    \n#&gt; carbodyhardtop        -3691.743   1424.825  -2.591 0.010561 *  \n#&gt; carbodyhatchback      -3344.335   1238.359  -2.701 0.007757 ** \n#&gt; carbodysedan          -2292.820   1356.014  -1.691 0.093043 .  \n#&gt; carbodywagon          -3427.921   1490.285  -2.300 0.022885 *  \n#&gt; drivewheelfwd          -504.564   1076.623  -0.469 0.640030    \n#&gt; drivewheelrwd           -15.446   1268.070  -0.012 0.990299    \n#&gt; enginelocationrear     6643.492   2572.275   2.583 0.010806 *  \n#&gt; wheelbase               -30.197     92.776  -0.325 0.745294    \n#&gt; carlength               -29.740     51.672  -0.576 0.565824    \n#&gt; carwidth                731.819    244.533   2.993 0.003258 ** \n#&gt; carheight               123.195    134.607   0.915 0.361617    \n#&gt; curbweight                2.612      1.781   1.467 0.144706    \n#&gt; enginetypedohcv       -8541.957   4749.685  -1.798 0.074219 .  \n#&gt; enginetypel             978.748   1786.384   0.548 0.584619    \n#&gt; enginetypeohc          3345.252    933.001   3.585 0.000461 ***\n#&gt; enginetypeohcf          972.919   1625.631   0.598 0.550462    \n#&gt; enginetypeohcv        -6222.322   1236.415  -5.033 1.43e-06 ***\n#&gt; cylindernumberfive   -11724.540   3019.192  -3.883 0.000157 ***\n#&gt; cylindernumberfour   -11549.326   3177.177  -3.635 0.000387 ***\n#&gt; cylindernumbersix     -7151.398   2247.230  -3.182 0.001793 ** \n#&gt; cylindernumberthree   -4318.929   4688.833  -0.921 0.358545    \n#&gt; cylindernumbertwelve -11122.209   4196.494  -2.650 0.008946 ** \n#&gt; enginesize              125.934     26.541   4.745 5.00e-06 ***\n#&gt; fuelsystem2bbl          177.136    883.615   0.200 0.841400    \n#&gt; fuelsystemmfi         -3041.018   2576.996  -1.180 0.239934    \n#&gt; fuelsystemmpfi          359.278   1001.529   0.359 0.720326    \n#&gt; fuelsystemspdi        -2543.890   1363.546  -1.866 0.064140 .  \n#&gt; fuelsystemspfi          514.766   2499.229   0.206 0.837107    \n#&gt; boreratio             -1306.740   1642.221  -0.796 0.427516    \n#&gt; stroke                -4527.137    922.732  -4.906 2.49e-06 ***\n#&gt; compressionratio       -737.901    555.960  -1.327 0.186539    \n#&gt; horsepower               10.293     22.709   0.453 0.651035    \n#&gt; peakrpm                   2.526      0.634   3.983 0.000108 ***\n#&gt; citympg                 -90.352    166.647  -0.542 0.588538    \n#&gt; highwaympg              154.858    167.148   0.926 0.355761    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2189 on 143 degrees of freedom\n#&gt; Multiple R-squared:  0.9415, Adjusted R-squared:  0.9264 \n#&gt; F-statistic: 62.21 on 37 and 143 DF,  p-value: &lt; 2.2e-16\n\n#choose 'horsepower' as the regressor\nhorsepower &lt;- data$horsepower\nprint(typeof(horsepower))\n\n#&gt; [1] \"double\"\n\nprint(range(horsepower))\n\n#&gt; [1]  48 288\n\n# The coefficient of 'horsepower' in the model gives us the effect on price\ncoef(model)[\"horsepower\"]\n\n#&gt; horsepower \n#&gt;   10.29354\n\n# The p-value of 'horsepower' in the model tells us about its statistical significance\nsummary(model)$coefficients[\"horsepower\", \"Pr(&gt;|t|)\"]\n\n#&gt; [1] 0.6510351\n\n\n\n4 Task 4\nassignment 5 no 4: Q : explain what data type it is and what values it can take on? A: the ‘horsepower’ variable is of numeric data type. This means it can take on any real number, Q : what effect is has on the price and what changing the value would have as a result? A : as horsepower increases, the price of the car also increases Q : whether its effect is statistically significant. A :\n\n5 Task 5\nQ : Add a variable seat_heating to the data and assign a value TRUE for all observations. You can use e.g. df %&gt;% mutate(new_variable = value). Assign it to a new object and run a regression. What coefficient do you get for the new variable seat_heating and how can you explain it?\n\ndata &lt;- data %&gt;% mutate(seat_heating = TRUE)\n\n# Run a regression with the new variable\nmodel_with_seat_heating &lt;- lm(price ~ ., data = data)\nsummary(model_with_seat_heating)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ ., data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt;  -5662  -1120      0    798   9040 \n#&gt; \n#&gt; Coefficients: (1 not defined because of singularities)\n#&gt;                        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)          -36269.965  15460.866  -2.346 0.020354 *  \n#&gt; aspirationturbo        1846.206   1041.391   1.773 0.078386 .  \n#&gt; doornumbertwo           242.523    571.929   0.424 0.672172    \n#&gt; carbodyhardtop        -3691.743   1424.825  -2.591 0.010561 *  \n#&gt; carbodyhatchback      -3344.335   1238.359  -2.701 0.007757 ** \n#&gt; carbodysedan          -2292.820   1356.014  -1.691 0.093043 .  \n#&gt; carbodywagon          -3427.921   1490.285  -2.300 0.022885 *  \n#&gt; drivewheelfwd          -504.564   1076.623  -0.469 0.640030    \n#&gt; drivewheelrwd           -15.446   1268.070  -0.012 0.990299    \n#&gt; enginelocationrear     6643.492   2572.275   2.583 0.010806 *  \n#&gt; wheelbase               -30.197     92.776  -0.325 0.745294    \n#&gt; carlength               -29.740     51.672  -0.576 0.565824    \n#&gt; carwidth                731.819    244.533   2.993 0.003258 ** \n#&gt; carheight               123.195    134.607   0.915 0.361617    \n#&gt; curbweight                2.612      1.781   1.467 0.144706    \n#&gt; enginetypedohcv       -8541.957   4749.685  -1.798 0.074219 .  \n#&gt; enginetypel             978.748   1786.384   0.548 0.584619    \n#&gt; enginetypeohc          3345.252    933.001   3.585 0.000461 ***\n#&gt; enginetypeohcf          972.919   1625.631   0.598 0.550462    \n#&gt; enginetypeohcv        -6222.322   1236.415  -5.033 1.43e-06 ***\n#&gt; cylindernumberfive   -11724.540   3019.192  -3.883 0.000157 ***\n#&gt; cylindernumberfour   -11549.326   3177.177  -3.635 0.000387 ***\n#&gt; cylindernumbersix     -7151.398   2247.230  -3.182 0.001793 ** \n#&gt; cylindernumberthree   -4318.929   4688.833  -0.921 0.358545    \n#&gt; cylindernumbertwelve -11122.209   4196.494  -2.650 0.008946 ** \n#&gt; enginesize              125.934     26.541   4.745 5.00e-06 ***\n#&gt; fuelsystem2bbl          177.136    883.615   0.200 0.841400    \n#&gt; fuelsystemmfi         -3041.018   2576.996  -1.180 0.239934    \n#&gt; fuelsystemmpfi          359.278   1001.529   0.359 0.720326    \n#&gt; fuelsystemspdi        -2543.890   1363.546  -1.866 0.064140 .  \n#&gt; fuelsystemspfi          514.766   2499.229   0.206 0.837107    \n#&gt; boreratio             -1306.740   1642.221  -0.796 0.427516    \n#&gt; stroke                -4527.137    922.732  -4.906 2.49e-06 ***\n#&gt; compressionratio       -737.901    555.960  -1.327 0.186539    \n#&gt; horsepower               10.293     22.709   0.453 0.651035    \n#&gt; peakrpm                   2.526      0.634   3.983 0.000108 ***\n#&gt; citympg                 -90.352    166.647  -0.542 0.588538    \n#&gt; highwaympg              154.858    167.148   0.926 0.355761    \n#&gt; seat_heatingTRUE             NA         NA      NA       NA    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2189 on 143 degrees of freedom\n#&gt; Multiple R-squared:  0.9415, Adjusted R-squared:  0.9264 \n#&gt; F-statistic: 62.21 on 37 and 143 DF,  p-value: &lt; 2.2e-16\n\n\nA : if the variable ‘seat heating’ is assigned to the data and is assigned a value ‘TRUE for all observations, obtained coefficient is ’NA’. This is because : iff an independent variable is constant and does not change across observations, it cannot explain any variation and its effect cannot be estimated, resulting in a NA coefficient in the regression output."
  },
  {
    "objectID": "content/01_journal/10_rdd.html",
    "href": "content/01_journal/10_rdd.html",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "Note\n\n\n\nAssignment X on Regression Discontinuity - final submission\n\n\n\nlibrary(dplyr)\n\n#&gt; Warning: package 'dplyr' was built under R version 4.2.3\n\n\n#&gt; \n#&gt; Attaching package: 'dplyr'\n\n\n#&gt; The following objects are masked from 'package:stats':\n#&gt; \n#&gt;     filter, lag\n\n\n#&gt; The following objects are masked from 'package:base':\n#&gt; \n#&gt;     intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\n#&gt; Warning: package 'ggplot2' was built under R version 4.2.3\n\ncoupon &lt;- readRDS(\"C:/Users/sophi/OneDrive/Desktop/Causal Data Science for Business Analytics 2023/gitclone/cdsba-swynona/assets/Causal_Data_Science_Data/coupon.rds\")\nshipping &lt;- readRDS(\"C:/Users/sophi/OneDrive/Desktop/Causal Data Science for Business Analytics 2023/gitclone/cdsba-swynona/assets/Causal_Data_Science_Data/shipping.rds\")\n\n# Define bandwidths\nhalf_bandwidth &lt;- max(coupon$days_since_last_centered) / 2\ndouble_bandwidth &lt;- max(coupon$days_since_last_centered) * 2\n\n# Filter data based on bandwidth\ndf_half &lt;- coupon %&gt;% filter(abs(days_since_last_centered) &lt;= half_bandwidth)\ndf_double &lt;- coupon %&gt;% filter(abs(days_since_last_centered) &lt;= double_bandwidth)\n\n# Run regression analyses\nmodel_half &lt;- lm(purchase_after ~ days_since_last_centered + coupon, data = df_half)\nmodel_double &lt;- lm(purchase_after ~ days_since_last_centered + coupon, data = df_double)\n\n# Print summary of models\nsummary(model_half)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = purchase_after ~ days_since_last_centered + coupon, \n#&gt;     data = df_half)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -15.1726  -2.7191  -0.4112   2.0888  31.4876 \n#&gt; \n#&gt; Coefficients:\n#&gt;                          Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)               8.95828    0.14414   62.15   &lt;2e-16 ***\n#&gt; days_since_last_centered -0.10701    0.00361  -29.64   &lt;2e-16 ***\n#&gt; couponTRUE               14.07541    0.26202   53.72   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 4.257 on 4919 degrees of freedom\n#&gt; Multiple R-squared:  0.4212, Adjusted R-squared:  0.421 \n#&gt; F-statistic:  1790 on 2 and 4919 DF,  p-value: &lt; 2.2e-16\n\nsummary(model_double)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = purchase_after ~ days_since_last_centered + coupon, \n#&gt;     data = df_double)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -15.005  -2.763  -0.453   2.063  32.047 \n#&gt; \n#&gt; Coefficients:\n#&gt;                           Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)               9.780254   0.133924   73.03   &lt;2e-16 ***\n#&gt; days_since_last_centered -0.083602   0.003258  -25.66   &lt;2e-16 ***\n#&gt; couponTRUE               13.085707   0.256153   51.09   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 4.321 on 4997 degrees of freedom\n#&gt; Multiple R-squared:  0.408,  Adjusted R-squared:  0.4078 \n#&gt; F-statistic:  1722 on 2 and 4997 DF,  p-value: &lt; 2.2e-16\n\nggplot(shipping, aes(x=purchase_amount)) +\n  geom_histogram(binwidth=1, fill=\"blue\", color=\"black\") +\n  geom_vline(aes(xintercept=30), color=\"red\", linetype=\"dashed\", linewidth=1) +\n  labs(title=\"Histogram of Purchase Amounts\",\n       x=\"Purchase Amount\",\n       y=\"Frequency\",\n       caption=\"Red line indicates the 30€ free shipping threshold\") +\n  theme_minimal()"
  },
  {
    "objectID": "content/01_journal/01_probability.html#b",
    "href": "content/01_journal/01_probability.html#b",
    "title": "Probability Theory",
    "section": "\n1.1 b",
    "text": "1.1 b"
  },
  {
    "objectID": "content/01_journal/01_probability.html#c",
    "href": "content/01_journal/01_probability.html#c",
    "title": "Probability Theory",
    "section": "\n2.1 c",
    "text": "2.1 c"
  },
  {
    "objectID": "content/01_journal/01_probability.html#d",
    "href": "content/01_journal/01_probability.html#d",
    "title": "Probability Theory",
    "section": "\n3.1 d",
    "text": "3.1 d"
  },
  {
    "objectID": "content/01_journal/01_probability.html#result-assignment-2",
    "href": "content/01_journal/01_probability.html#result-assignment-2",
    "title": "Probability Theory",
    "section": "\n2.1 Result Assignment 2",
    "text": "2.1 Result Assignment 2\n\n# Print the answers\nprint(paste(\"Percentage of customers using all three devices: \", percentage_all_three_devices, \"%\"))\n\n#&gt; [1] \"Percentage of customers using all three devices:  0.5 %\"\n\nprint(paste(\"Percentage of customers using at least two devices: \", percentage_at_least_two_devices, \"%\"))\n\n#&gt; [1] \"Percentage of customers using at least two devices:  19.9 %\"\n\nprint(paste(\"Percentage of customers using only one device: \", percentage_only_one_device, \"%\"))\n\n#&gt; [1] \"Percentage of customers using only one device:  80.1 %\""
  },
  {
    "objectID": "content/01_journal/01_probability.html#result-assignment-3",
    "href": "content/01_journal/01_probability.html#result-assignment-3",
    "title": "Probability Theory",
    "section": "\n3.1 Result Assignment 3",
    "text": "3.1 Result Assignment 3\n\n# Print the answers\n\nprint(paste(\"These results show than in case the alarm is triggered, there is a posibility of about \",P_not_A_given_B,\" % that the product is flawless and a probability of \", P_A_given_B, \" % that the product is faulty\"))\n\n#&gt; [1] \"These results show than in case the alarm is triggered, there is a posibility of about  19.8347107438017  % that the product is flawless and a probability of  80.1652892561983  % that the product is faulty\""
  },
  {
    "objectID": "content/01_journal/01_probability.html#result",
    "href": "content/01_journal/01_probability.html#result",
    "title": "Probability Theory",
    "section": "\n1.1 Result",
    "text": "1.1 Result\n\n#results\ncat(\"P(T ∩ S) = \", p_T_and_S, \"\\n\")\n\n#&gt; P(T ∩ S) =  0.06\n\ncat(\"P(T ∩ S') = \", p_T_and_S_prime, \"\\n\")\n\n#&gt; P(T ∩ S') =  0.42\n\ncat(\"P(T' ∩ S) = \", p_T_prime_and_S, \"\\n\")\n\n#&gt; P(T' ∩ S) =  0.24\n\ncat(\"P(T' ∩ S') = \", p_T_prime_and_S_prime, \"\\n\")\n\n#&gt; P(T' ∩ S') =  0.28\n\n#sum of all four probabilities\nsum_prob = p_T_and_S + p_T_and_S_prime + p_T_prime_and_S + p_T_prime_and_S_prime\ncat(\"The sum of all four probabilities = \", sum_prob, \"\\n\")\n\n#&gt; The sum of all four probabilities =  1"
  },
  {
    "objectID": "content/01_journal/01_probability.html#result-1",
    "href": "content/01_journal/01_probability.html#result-1",
    "title": "Probability Theory",
    "section": "\n2.1 Result",
    "text": "2.1 Result\n\n# Print the answers\nprint(paste(\"Percentage of customers using all three devices: \", percentage_all_three_devices, \"%\"))\n\n#&gt; [1] \"Percentage of customers using all three devices:  0.5 %\"\n\nprint(paste(\"Percentage of customers using at least two devices: \", percentage_at_least_two_devices, \"%\"))\n\n#&gt; [1] \"Percentage of customers using at least two devices:  19.9 %\"\n\nprint(paste(\"Percentage of customers using only one device: \", percentage_only_one_device, \"%\"))\n\n#&gt; [1] \"Percentage of customers using only one device:  80.1 %\""
  },
  {
    "objectID": "content/01_journal/01_probability.html#result-2",
    "href": "content/01_journal/01_probability.html#result-2",
    "title": "Probability Theory",
    "section": "\n3.1 Result",
    "text": "3.1 Result\n\n# Print the answers\n\nprint(paste(\"These results show than in case the alarm is triggered, there is a posibility of about \",P_not_A_given_B,\" % that the product is flawless and a probability of \", P_A_given_B, \" % that the product is faulty\"))\n\n#&gt; [1] \"These results show than in case the alarm is triggered, there is a posibility of about  19.8347107438017  % that the product is flawless and a probability of  80.1652892561983  % that the product is faulty\""
  },
  {
    "objectID": "content/01_journal/07_matching.html#nearest-neighbor-matching",
    "href": "content/01_journal/07_matching.html#nearest-neighbor-matching",
    "title": "Matching and Subclassification",
    "section": "\n3.1 Nearest Neighbor Matching",
    "text": "3.1 Nearest Neighbor Matching\n\n#Nearest Neighbor Matching\nmatch_nn &lt;- matchit(card ~ age + sex + pre_avg_purch, data = data, method = \"nearest\")\nmatched_data_nn &lt;- match.data(match_nn)\nATE_nn &lt;- with(matched_data_nn, mean(avg_purch[card == 1]) - mean(avg_purch[card == 0]))\nprint(paste(\"ATE after Nearest-Neighbor Matching: \", ATE_nn))\n\n#&gt; [1] \"ATE after Nearest-Neighbor Matching:  17.4018004817322\""
  },
  {
    "objectID": "content/01_journal/07_matching.html#inverse-probability-weighting-ipw",
    "href": "content/01_journal/07_matching.html#inverse-probability-weighting-ipw",
    "title": "Matching and Subclassification",
    "section": "\n3.2 Inverse Probability Weighting (IPW)",
    "text": "3.2 Inverse Probability Weighting (IPW)\n\n#Inverse Probability Weighting (IPW)\n# (1) Propensity scores\nmodel_prop &lt;- glm(card ~ age + sex + pre_avg_purch,\n                  data = data, # use 'data' instead of 'df'\n                  family = binomial(link = \"logit\"))\nsummary(model_prop)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = card ~ age + sex + pre_avg_purch, family = binomial(link = \"logit\"), \n#&gt;     data = data)\n#&gt; \n#&gt; Deviance Residuals: \n#&gt;     Min       1Q   Median       3Q      Max  \n#&gt; -1.6229  -1.0439  -0.8521   1.2370   1.8271  \n#&gt; \n#&gt; Coefficients:\n#&gt;                 Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept)   -1.4298676  0.0752043 -19.013   &lt;2e-16 ***\n#&gt; age            0.0011486  0.0017761   0.647    0.518    \n#&gt; sex            0.0359388  0.0412622   0.871    0.384    \n#&gt; pre_avg_purch  0.0148262  0.0009264  16.003   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 13626  on 9999  degrees of freedom\n#&gt; Residual deviance: 13249  on 9996  degrees of freedom\n#&gt; AIC: 13257\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4\n\n# Add propensities to table\ndata_aug &lt;- data %&gt;% mutate(propensity = predict(model_prop, type = \"response\")) # use 'data' instead of 'df'\n\n# Extend data by IPW scores\ndata_ipw &lt;- data_aug %&gt;% mutate(\n  ipw = (card/propensity) + ((1-card) / (1-propensity)))\n\n# Look at data with IPW scores\ndata_ipw %&gt;% \n  select(card, age, sex, pre_avg_purch, propensity, ipw)\n\n\n\n  \n\n\n# (2) Estimation\nmodel_ipw &lt;- lm(avg_purch ~ card,\n                data = data_ipw, # use 'data_ipw' instead of 'df_ipw'\n                weights = ipw)\nsummary(model_ipw)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = avg_purch ~ card, data = data_ipw, weights = ipw)\n#&gt; \n#&gt; Weighted Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -205.353  -28.995   -0.275   28.787  214.307 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  70.2628     0.4320  162.66   &lt;2e-16 ***\n#&gt; card         14.9573     0.6109   24.48   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 43.19 on 9998 degrees of freedom\n#&gt; Multiple R-squared:  0.05657,    Adjusted R-squared:  0.05647 \n#&gt; F-statistic: 599.5 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\n# Plot histogram of estimated propensities\nggplot(data_aug, aes(x = propensity)) + # use 'data_aug' instead of 'df_aug'\n  geom_histogram(alpha = .8, color = \"white\")\n\n#&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n# Run with high weights excluded\nmodel_ipw_trim &lt;- lm(avg_purch ~ card,\n                     data = data_ipw %&gt;% filter(propensity %&gt;% between(0.15, 0.85)), # use 'data_ipw' instead of 'df_ipw'\n                     weights = ipw)\nsummary(model_ipw_trim)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = avg_purch ~ card, data = data_ipw %&gt;% filter(propensity %&gt;% \n#&gt;     between(0.15, 0.85)), weights = ipw)\n#&gt; \n#&gt; Weighted Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -205.353  -28.995   -0.275   28.787  214.307 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  70.2628     0.4320  162.66   &lt;2e-16 ***\n#&gt; card         14.9573     0.6109   24.48   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 43.19 on 9998 degrees of freedom\n#&gt; Multiple R-squared:  0.05657,    Adjusted R-squared:  0.05647 \n#&gt; F-statistic: 599.5 on 1 and 9998 DF,  p-value: &lt; 2.2e-16"
  }
]